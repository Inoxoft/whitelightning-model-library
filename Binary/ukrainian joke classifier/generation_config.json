{
  "summary": "Classify a given message as either a joke or not a joke based on its content.",
  "classification_type": "binary_sigmoid",
  "class_labels": [
    "0",
    "1"
  ],
  "prompts": {
    "1": "Generate a diverse set of humorous text messages that are unmistakably intended as jokes. Include a wide range of humor styles such as puns, wordplay, one-liners, absurd scenarios, light teasing, and funny anecdotes. Cover varied tones (silly, witty, sarcastic, playful) and topics (daily life, food, technology, relationships, pop culture, animals). Ensure the messages are short, conversational, and feel authentic as if sent between friends or family. Avoid ambiguity—each message should clearly aim to amuse. Exclude offensive, controversial, or inappropriate content. Provide examples in natural, everyday language that reflect humor across different cultures or contexts where possible.",
    "0": "Generate a diverse set of non-humorous text messages that are clearly not jokes. Include a broad spectrum of content such as serious updates, informational messages, reminders, questions, casual check-ins, and planning discussions. Cover varied contexts (work, personal life, emergencies, travel, hobbies) and tones (formal, friendly, neutral, urgent, concerned). Ensure the messages are short, conversational, and realistic, as if sent between friends, family, or colleagues. Avoid any hint of humor, sarcasm, or playfulness to prevent misclassification. Use natural, everyday language that reflects a range of communication styles and purposes."
  },
  "model_prefix": "joke_classifier",
  "training_data_volume": 2000,
  "parameters": {
    "problem_description": "Classify message as joke or not joke",
    "selected_data_gen_model": "mistralai/mistral-nemo",
    "output_base_path": "models",
    "config_model": "x-ai/grok-3-beta",
    "batch_size": 10,
    "prompt_refinement_cycles": 1,
    "generate_edge_cases": true,
    "edge_case_volume_per_class": 50,
    "analyze_performance_data_path": null,
    "language": "ukrainian",
    "max_features_tfidf": 5000
  },
  "training_duplicate_stats": {
    "total_samples": 4534,
    "unique_samples": 4362,
    "duplicate_count": 172,
    "duplicate_rate": 3.79,
    "exceeds_threshold": false,
    "threshold": 5.0,
    "examples": [
      {
        "text": "\"(Bought a new car and found out it has a system that automatically opens and closes windows. Now I ...",
        "count": 2
      },
      {
        "text": "\"(Bought a new laptop, and my friends said I can't work on it. I told them it's because I'm too busy...",
        "count": 2
      },
      {
        "text": "\"(Bought a new smartphone, and my friends said I can't unlock it. I told them it's because I'm too b...",
        "count": 2
      }
    ]
  },
  "edge_case_prompts": {
    "0": "\n**Goal:** Generate challenging examples for the class \"0\" for testing a binary_sigmoid classifier.\n\n**Problem Description:** Classify message as joke or not joke\n**All Class Labels:** ['0', '1']\n\n**Task:** Generate diverse text samples that ARE examples of \"0\" according to the Problem Description, but are intentionally designed to be difficult for a classifier to identify correctly. Focus on:\n*   Borderline cases that barely meet the \"0\" criteria.\n*   Examples disguised to look like other classes (e.g., subtle \"0\" signals).\n*   Samples using unusual phrasing, jargon, or obfuscation related to the \"0\" class.\n*   Ambiguous examples that require careful reading to identify as \"0\".\n\nGenerate only the text samples, in json format using numbers as keys. Do not add labels or explanations. Samples should be in ukrainian language.\n",
    "1": "\n**Goal:** Generate challenging examples for the class \"1\" for testing a binary_sigmoid classifier.\n\n**Problem Description:** Classify message as joke or not joke\n**All Class Labels:** ['0', '1']\n\n**Task:** Generate diverse text samples that ARE examples of \"1\" according to the Problem Description, but are intentionally designed to be difficult for a classifier to identify correctly. Focus on:\n*   Borderline cases that barely meet the \"1\" criteria.\n*   Examples disguised to look like other classes (e.g., subtle \"1\" signals).\n*   Samples using unusual phrasing, jargon, or obfuscation related to the \"1\" class.\n*   Ambiguous examples that require careful reading to identify as \"1\".\n\nGenerate only the text samples, in json format using numbers as keys. Do not add labels or explanations. Samples should be in ukrainian language.\n"
  },
  "edge_case_duplicate_stats": {
    "total_samples": 15,
    "unique_samples": 15,
    "duplicate_count": 0,
    "duplicate_rate": 0.0,
    "exceeds_threshold": false,
    "threshold": 5.0,
    "examples": []
  },
  "performance_analysis": {
    "input_file": "models/joke_classifier/joke_classifier_edge_case_predictions.csv",
    "llm_analysis": "### Summary\nThe binary classifier for distinguishing between joke (class 1) and non-joke (class 0) text messages shows mixed performance based on the provided test results. The model struggles primarily with non-joke messages that reference humor or failed attempts at humor, often misclassifying them as jokes (class 1). Conversely, it occasionally misclassifies clear jokes as non-jokes (class 0), particularly when the humor is subtle or context-dependent. However, the model performs well on straightforward jokes with obvious punchlines and unambiguous non-humorous messages. Below, I analyze the weaknesses and strengths of the model and suggest targeted improvements to the data generation process to address the identified issues.\n\n---\n\n### 1. Analyze Weaknesses\nThe test results reveal specific patterns of confusion and challenges for the model:\n\n- **Class 0 (Non-Joke) Misclassifications as Class 1 (Joke):**\n  - The most prominent weakness is the model's tendency to misclassify non-joke messages as jokes when the text mentions humor, jokes, or failed attempts at being funny. Examples like \"Я сьогодні так втомився на роботі, що навіть не можу придумати нічого смішного...\" and \"Слухай, у мене є ідея для жарту, але вона настільки погана, що краще я її просто залишу при собі\" are labeled as non-jokes (0) but predicted as jokes (1). This suggests the model is overly sensitive to keywords related to humor (e.g., \"жарт,\" \"смішного,\" \"пожартувати\") without considering the overall intent or tone of the message, which indicates a lack of contextual understanding.\n  - These examples often describe a failed or absent attempt at humor, which may confuse the model since it associates any mention of humor with class 1. This indicates a gap in the training data for non-joke messages that reference humor in a non-humorous way.\n\n- **Class 1 (Joke) Misclassifications as Class 0 (Non-Joke):**\n  - The model occasionally fails to recognize jokes, particularly when the humor is subtle, context-dependent, or lacks an obvious punchline. For instance, \"Ти чув про той новий ресторан на Місяці? Їжа там непогана, але атмосфери взагалі немає\" is a clear pun-based joke (playing on \"atmosphere\" as both ambiance and literal air), but it was misclassified as non-joke (0). Similarly, \"Сьогодні на роботі було так нудно, що я почав рахувати, скільки разів шеф скаже 'продуктивність'...\" is a lighthearted, anecdotal joke but was also misclassified.\n  - These errors suggest the model struggles with jokes that rely on cultural context, wordplay, or understated humor, possibly due to insufficient representation of such examples in the training data or a bias toward more overt humor styles.\n\n- **General Challenges:**\n  - **Ambiguity in Intent:** Messages that blur the line between humor and non-humor (e.g., failed jokes or mentions of humor without being humorous) are particularly challenging. The model lacks the ability to discern intent, focusing instead on surface-level cues like humor-related keywords.\n  - **Language and Cultural Nuances:** Some misclassifications may stem from language-specific or cultural nuances in humor (e.g., puns or idiomatic expressions) that the model does not fully capture, especially if the training data lacks diversity in linguistic styles or cultural contexts.\n\n---\n\n### 2. Identify Strengths\nDespite the weaknesses, the model demonstrates clear strengths in certain areas:\n\n- **Class 1 (Joke) Correct Predictions:**\n  - The model performs well on straightforward, unambiguous jokes with clear punchlines or classic humor structures. Examples like \"Чому математики такі погані у стосунках? Бо вони завжди шукають ікс, але ніколи не питають, чому\" and \"Я запитав у друга, чому він завжди запізнюється. Він відповів, що просто живе за іншим часовим поясом... у своїй голові\" were correctly classified as jokes (1). These cases often involve obvious wordplay, absurdity, or direct humor, suggesting the model has learned to recognize overt comedic patterns effectively.\n  - This strength indicates that the training data for class 1 adequately covers a range of humor styles when the intent to amuse is clear.\n\n- **Class 0 (Non-Joke) Correct Predictions:**\n  - The model correctly identifies non-humorous messages that do not reference humor or joking at all. For instance, cases like \"Знаєш, я намагався сказати щось кумедне на зустрічі, але всі дивилися на мене, ніби я говорю іншою мовою\" and \"На вечірці я намагався бути дотепним, але мої слова звучали як звичайна розмова про буденність\" were correctly classified as non-jokes (0), though these are borderline cases. When the tone is clearly serious or neutral without humor-related keywords, the model performs reliably.\n  - This suggests the training data for class 0 is effective for purely non-humorous content, though it struggles with edge cases.\n\n---\n\n### 3. Suggest Improvements\nTo address the identified weaknesses while building on the model's strengths, I recommend the following improvements focused on the data generation process. These suggestions aim to refine the prompts for each class and introduce more diverse, challenging examples to better train the model on ambiguous and context-dependent cases.\n\n#### General Recommendations:\n- **Increase Representation of Borderline Cases:** The model struggles with messages that lie on the boundary between joke and non-joke (e.g., failed humor attempts, subtle jokes). Future data generation should explicitly include more of these ambiguous cases for both classes to help the model learn to distinguish intent and tone beyond surface-level keywords.\n- **Enhance Contextual Diversity:** Ensure the training data includes a wider range of linguistic styles, cultural contexts, and humor types to improve the model's ability to handle language-specific nuances and subtle humor.\n\n#### Specific Recommendations for Class 0 (Non-Joke):\n- **Modify Prompt to Include Humor References Without Humor Intent:**\n  - **Current Issue:** The existing prompt for class 0 explicitly avoids \"any hint of humor, sarcasm, or playfulness,\" which likely results in a lack of examples where humor is referenced in a non-humorous way (e.g., failed jokes or discussions about humor). This gap contributes to misclassifications when such references appear in test data.\n  - **Suggested Prompt Modification:** Revise the prompt to include a subset of messages that mention humor or joking in a serious or neutral context. For example:\n    - *Revised Prompt Addition:* \"Include a subset of messages that reference humor, jokes, or attempts at being funny in a non-humorous way, such as describing failed jokes, expressing inability to be funny, or discussing humor seriously without intending to amuse. Ensure these messages maintain a neutral or serious tone and are clearly not intended as jokes.\"\n  - **Example Output from Revised Prompt:** \"I tried to make a joke at the meeting, but it fell flat, and now I just feel embarrassed.\" (Label: 0)\n  - **Rationale:** This will expose the model to non-joke messages with humor-related keywords, teaching it to prioritize overall tone and intent over specific words.\n\n- **Increase Tone and Topic Variety:** Ensure the non-joke data includes a broader range of tones (e.g., frustration, disappointment, or neutrality when discussing humor) and topics (e.g., work, social interactions) to mirror real-world scenarios where humor might be referenced without humorous intent.\n\n#### Specific Recommendations for Class 1 (Joke):\n- **Modify Prompt to Include Subtle and Context-Dependent Humor:**\n  - **Current Issue:** The existing prompt for class 1 focuses on \"unmistakably intended\" jokes, which may over-represent overt humor and under-represent subtle or context-dependent humor (e.g., puns, cultural references, or understated anecdotes). This contributes to misclassifications of less obvious jokes.\n  - **Suggested Prompt Modification:** Expand the prompt to explicitly include subtle humor and jokes that rely on context or cultural knowledge. For example:\n    - *Revised Prompt Addition:* \"Include a subset of jokes that are subtle, understated, or rely on cultural context, wordplay, or specific knowledge for humor. These jokes may not have an obvious punchline but should still be intended to amuse in a conversational way.\"\n  - **Example Output from Revised Prompt:** \"I told my boss I’m working at 100% capacity. He didn’t realize I meant 100% capacity for procrastination.\" (Label: 1)\n  - **Rationale:** This will help the model learn to recognize humor beyond overt punchlines, improving performance on subtle or nuanced jokes.\n\n- **Augment Data with Diverse Humor Styles:** Ensure the training data includes humor from varied cultural backgrounds, idiomatic expressions, and language-specific puns to address misclassifications due to cultural or linguistic nuances. For instance, generate jokes in multiple languages or dialects if the model is expected to handle multilingual data.\n\n#### Data Augmentation Ideas:\n- **Synthetic Borderline Cases:** Generate synthetic examples that intentionally blur the line between joke and non-joke by combining elements of both classes. For example:\n  - Non-Joke with Humor Reference: \"I wanted to tell a joke about time travel, but I couldn’t think of anything good.\" (Label: 0)\n  - Subtle Joke: \"My calendar is so full, it’s basically a bestseller.\" (Label: 1)\n  - **Rationale:** These examples will challenge the model to focus on intent and tone rather than keywords.\n- **Paraphrasing and Contextual Variations:**",
    "accuracy_from_file": 0.3333333333333333
  },
  "generation_timestamp": "2025-06-25T12:03:03.733101",
  "prompt_refinement_history": [
    {
      "cycle": 1,
      "evaluation": "The current prompts and sample data show a reasonable distinction between the 'joke' (1) and 'not joke' (0) classes. For class '0', the samples are appropriately neutral or serious, covering reminders and casual conversation, though they lack tonal and contextual diversity (e.g., urgent or professional tones are underrepresented). For class '1', the samples include humor via puns and wordplay, but the diversity in humor types (e.g., situational or absurd) and clarity of intent as a joke could be improved. Some translations or phrasing in both classes seem awkward or unnatural, potentially due to language nuances. Overall, the prompts are functional but can be refined for greater diversity, specificity, and natural conversational flow to enhance classifier performance.",
      "previous_prompts": {
        "1": "Generate a diverse set of humorous text messages that are unmistakably intended as jokes. Include a wide range of humor styles such as puns, wordplay, one-liners, absurd scenarios, light teasing, and funny anecdotes. Cover varied tones (silly, witty, sarcastic, playful) and topics (daily life, food, technology, relationships, pop culture, animals). Ensure the messages are short, conversational, and feel authentic as if sent between friends or family. Avoid ambiguity—each message should clearly aim to amuse. Exclude offensive, controversial, or inappropriate content. Provide examples in natural, everyday language that reflect humor across different cultures or contexts where possible.",
        "0": "Generate a diverse set of non-humorous text messages that are clearly not jokes. Include a broad spectrum of content such as serious updates, informational messages, reminders, questions, casual check-ins, and planning discussions. Cover varied contexts (work, personal life, emergencies, travel, hobbies) and tones (formal, friendly, neutral, urgent, concerned). Ensure the messages are short, conversational, and realistic, as if sent between friends, family, or colleagues. Avoid any hint of humor, sarcasm, or playfulness to prevent misclassification. Use natural, everyday language that reflects a range of communication styles and purposes."
      },
      "refined_prompts": {
        "1": "Generate a diverse set of humorous text messages that are unmistakably intended as jokes. Include a wide range of humor styles such as puns, wordplay, one-liners, absurd scenarios, light teasing, and funny anecdotes. Cover varied tones (silly, witty, sarcastic, playful) and topics (daily life, food, technology, relationships, pop culture, animals). Ensure the messages are short, conversational, and feel authentic as if sent between friends or family. Avoid ambiguity—each message should clearly aim to amuse. Exclude offensive, controversial, or inappropriate content. Provide examples in natural, everyday language that reflect humor across different cultures or contexts where possible.",
        "0": "Generate a diverse set of non-humorous text messages that are clearly not jokes. Include a broad spectrum of content such as serious updates, informational messages, reminders, questions, casual check-ins, and planning discussions. Cover varied contexts (work, personal life, emergencies, travel, hobbies) and tones (formal, friendly, neutral, urgent, concerned). Ensure the messages are short, conversational, and realistic, as if sent between friends, family, or colleagues. Avoid any hint of humor, sarcasm, or playfulness to prevent misclassification. Use natural, everyday language that reflects a range of communication styles and purposes."
      }
    }
  ],
  "output_paths": {
    "main_output_directory": "models/joke_classifier",
    "training_data": "models/joke_classifier/training_data.csv",
    "edge_case_data": "models/joke_classifier/edge_case_data.csv",
    "raw_api_responses": "models/joke_classifier/api_requests",
    "final_config_file": "models/joke_classifier/generation_config.json",
    "trained_model_prefix": "models/joke_classifier/joke_classifier",
    "onnx_model_path": "models/joke_classifier/joke_classifier.onnx",
    "performance_predictions_csv": "models/joke_classifier/joke_classifier_edge_case_predictions.csv"
  }
}